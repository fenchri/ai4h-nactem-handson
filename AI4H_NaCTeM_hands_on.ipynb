{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI4H-NaCTeM_hands-on.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "ADgPa-Rx0YnJ",
        "rRfWBH6JPjRE",
        "XCnhluvObF70",
        "6_i1RrjWclpe",
        "aBgzuPEtb3vI",
        "SOZq5gYxEOUg",
        "vdx8Og_WaPI1",
        "pokH5jeykegG",
        "sz7Xu5N1sp9M",
        "0sQOTxCMYSAy",
        "51CofOMe_uPX",
        "TorKbeDsQL2V",
        "aBaUs55uAnfE",
        "eOJvv4WCBAB4",
        "CD72QS_EA_yK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fenchri/ai4h-nactem-handson/blob/main/AI4H_NaCTeM_hands_on.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADgPa-Rx0YnJ"
      },
      "source": [
        "# Welcome to the AI4H Winter School NaCTeM session ! ðŸŽ‰ \n",
        "\n",
        "The goal of this session is to give you a practical overview of how you can create an end-to-end pipeline model for Event Extraction. The code used in all of the following sections is packed up into a repository, which you can use to try on your own.\n",
        "After you get the grasp of the main components the of the system, you can try to change the model architecture in order to further improve performance, using methods that we discussed during the morning session.\n",
        "\n",
        "This notebook is divided into the following sections:  \n",
        "1. Set up environment\n",
        "2. Checking out the data\n",
        "3. Named Entity Recognition\n",
        "4. Relation Extraction\n",
        "5. Event Extraction\n",
        "6. Pipeline Performance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRfWBH6JPjRE"
      },
      "source": [
        "# Step 1: Import the code directory & install dependencies\n",
        "\n",
        "Replace the *\\<insert_token_here\\>* part in the next cell with the gitlab token that will be provided to you during the session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjAX2__bQI7-"
      },
      "source": [
        "!git clone https://ai4h-nactem-participants:BJ2Htni9pMiYH6cqxUcY@gitlab.com/fenchri/ai4health-nactem.git\n",
        "#!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5y84sVDZU-P"
      },
      "source": [
        "import os\n",
        "directory_path = \"/content/ai4health-nactem/\"\n",
        "os.chdir(directory_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ZsCnm6ZWuT"
      },
      "source": [
        "# Installing requirements may take a few minutes ...\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ogqYqW340Ek"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "In order to evaluate the three networks of interest, we will incorporate the standard machine learning evaluation metrics of Preciion (P), Recall (R) and F1-score. \n",
        "In order to estimate each of these metrics we need to define the following:\n",
        "- **TP** (True Positives): Number of instances correctly identified by the model\n",
        "- **FP** (False Positives): Number of instances false identified by the model\n",
        "- **FN** (False Negatives): Number of instances missed by the model\n",
        "\n",
        "Then, we can calculate each of these metrics as follows:\n",
        "\n",
        "$ P = \\frac{TP}{TP + FP} $, $ R = \\frac{TP}{TP + FN} $, $ F1 = \\frac{2 P R }{P + R} $\n",
        "\n",
        "> Note: The sum of $TP + FP$ essentially corresponds to all *predicted* instances, while the sum of $TP + FN$ corresponds to all *true* instances.\n",
        "\n",
        "We can then estime micro- and macro-averaged version of these metrics as follows\n",
        "$ P_\\text{micro} = \\frac{\\sum_c TP_c}{\\sum_c TP_c + FP_c} $, \n",
        "$ P_\\text{macro} = \\frac{1}{|c|} \\sum_c P_c $\n",
        "\n",
        "The micro-average measures the total performance across all instances, while the macro-average measures the performance for each category separately and takes the average values across categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCnhluvObF70"
      },
      "source": [
        "# Step 2: Checking out the data\n",
        "\n",
        "In this step we will have an initial look at the dataset we are going to use. \n",
        "In particular, we will make use of the [MLEE (Multi-level Event Extraction)](http://nactem.ac.uk/MLEE/) by [Pyysalo et al. (2012)](https://academic-oup-com.manchester.idm.oclc.org/bioinformatics/article/28/18/i575/249872) in order to perform Event Extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_i1RrjWclpe"
      },
      "source": [
        "## Step 2a: Inspecting the data\n",
        "\n",
        "The dataset can be parser via the [brat](https://brat.nlplab.org/) annotation tool. In the following link you can navigate across the entire collection of documents in MLEE using the arrows.\n",
        "\n",
        "http://www.nactem.ac.uk/eccb2012/index.xhtml#/10417401"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBgzuPEtb3vI"
      },
      "source": [
        "## Step 2b: Data Statistics \n",
        "\n",
        "Lets delve into the dataset statistics, in terms of named entities, events, etc.Run the following cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "709CTh_ZcVqJ"
      },
      "source": [
        "% cd /content/ai4health-nactem/src\n",
        "\n",
        "from statistics import calc_statistics\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_keys(report,keys,main_value, sec_value):\n",
        "  values = []\n",
        "  for key in keys:\n",
        "    if key in report[main_value][sec_value]:\n",
        "      val = report[main_value][sec_value][key]['count']\n",
        "      #print(val)\n",
        "      values.append(val)\n",
        "    else:\n",
        "      values.append(0)\n",
        "  return(values)\n",
        "\n",
        "\n",
        "report_train = calc_statistics('train')  # get statistics\n",
        "report_val = calc_statistics('val')\n",
        "report_test = calc_statistics('test')\n",
        "\n",
        "main_value = 'Entities'\n",
        "sec_value = 'Types'\n",
        "keys = list(report_test[main_value][sec_value].keys())\n",
        "\n",
        "x_train = get_keys(report_train, keys, main_value, sec_value)\n",
        "x_val = get_keys(report_val, keys, main_value, sec_value)\n",
        "x_test = get_keys(report_test, keys, main_value, sec_value)\n",
        "y = np.arange(len(keys))\n",
        "#print(y)\n",
        "ax = plt.subplot(111)\n",
        "train = ax.bar(y-0.3, x_train, width=0.3, color='tab:blue', align='center')\n",
        "val = ax.bar(y+0.0, x_val, width=0.3, color='tab:green', align='center')\n",
        "test = ax.bar(y+0.3, x_test, width=0.3, color='tab:orange', align='center')\n",
        "ax.legend( [train, val, test], ['train', 'dev', 'test'] )\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "plt.rcParams['figure.dpi'] = 90 \n",
        "plt.xticks(y, keys)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Entity Counts')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('Total Entities:', (report_train['Entities']['Total']['count']+report_val['Entities']['Total']['count']+report_test['Entities']['Total']['count']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSJiR5D_cYMI"
      },
      "source": [
        "\n",
        "main_value = 'Triggers'\n",
        "sec_value = 'Types'\n",
        "keys = list(report_test[main_value][sec_value].keys())\n",
        "\n",
        "x_train = get_keys(report_train, keys, main_value, sec_value)\n",
        "x_val = get_keys(report_val, keys, main_value, sec_value)\n",
        "x_test = get_keys(report_test, keys, main_value, sec_value)\n",
        "\n",
        "\n",
        "y = np.arange(len(keys))\n",
        "#print(y)\n",
        "ax = plt.subplot(111)\n",
        "train = ax.bar(y-0.3, x_train, width=0.3, color='tab:blue', align='center')\n",
        "val = ax.bar(y+0.0, x_val, width=0.3, color='tab:green', align='center')\n",
        "test = ax.bar(y+0.3, x_test, width=0.3, color='tab:orange', align='center')\n",
        "ax.legend( [train, val, test], ['train', 'dev', 'test'] )\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "plt.rcParams['figure.dpi'] = 90 \n",
        "plt.xticks(y, keys)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Trigger Counts')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('Total Triggers:', (report_train[main_value]['Total']['count']+report_val[main_value]['Total']['count']+report_test[main_value]['Total']['count']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grZlPb2PPJ6n"
      },
      "source": [
        "\n",
        "main_value = 'Events'\n",
        "sec_value = 'Roles'\n",
        "keys = list(report_test[main_value][sec_value].keys())\n",
        "\n",
        "x_train = get_keys(report_train, keys, main_value, sec_value)\n",
        "x_val = get_keys(report_val, keys, main_value, sec_value)\n",
        "x_test = get_keys(report_test, keys, main_value, sec_value)\n",
        "\n",
        "\n",
        "y = np.arange(len(keys))\n",
        "#print(y)\n",
        "ax = plt.subplot(111)\n",
        "train = ax.bar(y-0.3, x_train, width=0.3, color='tab:blue', align='center')\n",
        "val = ax.bar(y+0.0, x_val, width=0.3, color='tab:green', align='center')\n",
        "test = ax.bar(y+0.3, x_test, width=0.3, color='tab:orange', align='center')\n",
        "ax.legend( [train, val, test], ['train', 'dev', 'test'] )\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "plt.rcParams['figure.dpi'] = 90 \n",
        "plt.xticks(y, keys)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Event Role Counts')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "total = (report_train[main_value]['Total']['count']+report_val[main_value]['Total']['count']+report_test[main_value]['Total']['count'])\n",
        "total_nested =  (report_train[main_value]['Nested']['count']+report_val[main_value]['Total']['count']+report_test[main_value]['Nested']['count'])\n",
        "print('Total Events: ', total)\n",
        "print('Nested Events: {} ({:.2f} %)'.format(total_nested, 100 * total_nested / total))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEs1aJJPWE68"
      },
      "source": [
        "report['sent_len']['avg']\n",
        "report['sent_len']['max']\n",
        "report['sent_len']['min']\n",
        "\n",
        "report['sent_ents']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buOh4MknbVy_"
      },
      "source": [
        "report_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOZq5gYxEOUg"
      },
      "source": [
        "##Step 2c: Sample Sentence\n",
        "\n",
        "We will use the following sentence as out sample throughout the next modules.\n",
        "\n",
        "![Example  Sentence](\"/content/ai4health-nactem/images/example_sentence.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99mj68RFE6mx"
      },
      "source": [
        "from IPython.display import Image #, display\n",
        "#from google.colab.patches import cv2_imshow\n",
        "#import cv2\n",
        "\n",
        "example_image = '/content/ai4health-nactem/images/example_sentence.png'\n",
        "#img = cv2.imread(example_image, cv2.IMREAD_UNCHANGED)\n",
        "#cv2_imshow(img)\n",
        "Image(example_image, width='1200')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_OYDgedXXud"
      },
      "source": [
        "# Step 3: Named Entity Recognition\n",
        "\n",
        "The first we will investigate is Named Entity Recognition (NER). \n",
        "In this task, we will identify *named entities* and *triggers* in a given sentence simultaneously. \n",
        "We will treat this problem as a **token classification** task, i.e. we predict one label for each word in the sentence.\n",
        "We will incorporate a pre-trained Language Model and finetune it on the MLEE dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdx8Og_WaPI1"
      },
      "source": [
        "## Step 3a: Creating NER instances\n",
        "\n",
        "An instance in this task is considered a sentence.\n",
        "Since we treat NER as a token classification task, we need to associate each word with a particular label. We will thus incorporate the BIO tagging scheme that we saw earlier.\n",
        "As a reminder:\n",
        "- **B-CLASS** tag is assigned to the beginning tokens\n",
        "- **I-CLASS** tag is assigned to the intermediate (and last tokens)\n",
        "- **O** tag is assigned to all other tokens (not belonginning in an entity)\n",
        "\n",
        "This is already provided by our dataset, hence each sentence is associated with a particular BIO sequence, as seen in the example below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXegp4pRbEeS"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('/content/ai4health-nactem/data/MLEE_train.json', 'r') as f:\n",
        "    example = json.loads(f.readline())\n",
        "\n",
        "example_sentence = example['sentence']\n",
        "for w, l in zip(example_sentence, example['bio']):\n",
        "  print('{:<10}\\t{:<10}'.format(w, l))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIcBGQn3ZXNP"
      },
      "source": [
        "## Step 3b: Pre-processing sentences\n",
        "\n",
        "In order to feed each sentence into the model we first need to a apply a few basic pre-processing steps:\n",
        "- Tokenization\n",
        "- Subword segmentation\n",
        "- Conversion of elements to identifiers\n",
        "\n",
        "The dataset is already in a tokenized format, i.e. each word is separated by a space as we saw in step 3a. \n",
        "The most important (and tricky here) is subword tokenization.\n",
        "As we saw during the lecture, state-of-the-art language models use subword segmentation on the input sequence, before feeding it into the network.\n",
        "This means, that each word will need to be segmented based on the algorithm that each model uses (e.g. BPE, WordPiece, etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9Sq-QuGdBAQ"
      },
      "source": [
        "We first need to initialize a tokenizer as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHaZDN3RcMKl"
      },
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "            'roberta-base',\n",
        "            add_prefix_space=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c7vesE3dLV4"
      },
      "source": [
        "We can then pass the sentence into the tokenizer and inspect the output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IApKBxFdPWp"
      },
      "source": [
        "segmented_sentence = [tokenizer.tokenize(w) for w in example_sentence]\n",
        "segmented_sentence = [item for sublist in segmented_sentence for item in sublist]\n",
        "\n",
        "print('Original sentence:\\n{}\\n'.format(' | '.join(example_sentence)))\n",
        "print('Segmented sentence:\\n{}\\n'.format(' | '.join(segmented_sentence)))\n",
        "\n",
        "print(f'Original sentence length:  {len(example_sentence)}')\n",
        "print(f'Segmented sentence length: {len(segmented_sentence)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwyE-ZxWgI3m"
      },
      "source": [
        "As we can see the length of the sentence is now longer than before since for example: \n",
        "```\n",
        "extracellular --> extra ##cellular\n",
        "```\n",
        "\n",
        "This means we need to re-adjust the the labels we have, in order to have the same length in both sequences. We will do that using a \"trick\", to append an \"X\" label for each newly introduced subword.\n",
        "\n",
        "The following code shows the sentence in column 1 and the expected (extended) output labels in column 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPZ9Fb6WjdkJ"
      },
      "source": [
        "new_label_seq = []\n",
        "for w, l in zip(example_sentence, example['bio']):\n",
        "    w_ids = tokenizer.tokenize(w)\n",
        "    n_subwords = len(w_ids)  # augment labels based on number of subwords (X label)\n",
        "    new_label_seq += [l]\n",
        "    new_label_seq.extend(['X'] * (n_subwords - 1))\n",
        "\n",
        "for w, l in zip(segmented_sentence, new_label_seq):\n",
        "  print('{:<10}\\t{:<10}'.format(w, l))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p099-_QbkI3u"
      },
      "source": [
        "Now we simply need to convert each token and its label into a unique id, in order to feed them into the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNwTP1YWzwDO"
      },
      "source": [
        "from models.ner_dataset import NERdataset\n",
        "import yaml\n",
        "import torch\n",
        "from utils import *\n",
        "import yamlordereddictloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "with open('/content/ai4health-nactem/src/config.yaml', 'r') as f:\n",
        "  config = yaml.load(f, Loader=yamlordereddictloader.Loader)\n",
        "\n",
        "config = dict(config)\n",
        "device = torch.device(\"cuda:{}\".format(config['gpu']) if config['gpu'] != -1 else \"cpu\")\n",
        "config['device'] = device\n",
        "config['task'] = 'ner'\n",
        "\n",
        "config['labels'] = ner_labels(config)\n",
        "config['labels'].trigger_types = ner_triggers(config)\n",
        "config['unique_labels'] = list(set([l.split('-')[1] \n",
        "                                    for l in config['labels'].ent2id.keys()\n",
        "                                    if '-' in l]))\n",
        "\n",
        "train_data = NERdataset(config, tokenizer, 'train')\n",
        "train_loader = DataLoader(dataset=train_data,\n",
        "                          batch_size=config['batch_size'],\n",
        "                          shuffle=True,\n",
        "                          collate_fn=train_data.collate)\n",
        "\n",
        "for trd in train_loader:\n",
        "  for i, id_ in enumerate(trd['ids']):\n",
        "    if id_ == 'PMID-16407289-s0':\n",
        "      print(' === Sentence ===')\n",
        "      print(tokenizer.convert_ids_to_tokens(trd['input_ids'][i]))\n",
        "      print(trd['input_ids'][i])\n",
        "\n",
        "      print('\\n === Labels ===')\n",
        "      print([config['labels'].id2ent[l] for l in trd['labels'][i].tolist()])\n",
        "      print(trd['labels'][i])\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pokH5jeykegG"
      },
      "source": [
        "## Step 3c: NER Module\n",
        "\n",
        "We will use a very simple and straightforward NER component, as shown in the figure below.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9YUrQh5go9E"
      },
      "source": [
        "ner_arch = '/content/ai4health-nactem/images/ner-arch.png'\n",
        "Image(ner_arch, width=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUsYrXk0NpQr"
      },
      "source": [
        "The NER module written in [PyTorch](https://pytorch.org/) is shown below:\n",
        "It essentially consists of the encoder layer (a pretrained Transformer-based LM) and a classification - linear layer or a \"softmax\" layer.\n",
        "\n",
        "The linear layer is included inside the module, stacked on top of the encoder's output.\n",
        "\n",
        "During the forward computation, the outpus of the encoder are fed into a linear layer which has as output dimensionality equal to the number of target semantic types. \n",
        "The extracted values are normalised via a softmax activation function and the predicted label is the one with the highest probability score.\n",
        "\n",
        "\n",
        "```python\n",
        "class NERmodel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(NERmodel, self).__init__()\n",
        "\n",
        "        self.config = config\n",
        "        self.num_labels = config['labels'].n_ent\n",
        "        self.model_config = AutoConfig.from_pretrained(\n",
        "            config['model_name'],\n",
        "            num_labels=self.num_labels\n",
        "        )\n",
        "        self.encoder = AutoModelForTokenClassification.from_pretrained(config['model_name'],\n",
        "                                                                       config=self.model_config)\n",
        "        self.loss_fct = nn.CrossEntropyLoss(ignore_index=config['labels'].X_id)  # ignore masked subwords\n",
        "\n",
        "    def forward(self, seqs):\n",
        "        outputs = self.encoder(seqs['input_ids'],\n",
        "                               attention_mask=seqs['attention_mask'])\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        mask = torch.ne(seqs['input_ids'], self.model_config.pad_token_id)  # remove padding\n",
        "        active_logits = logits[mask]\n",
        "        active_labels = seqs['labels'][mask]\n",
        "\n",
        "        loss = self.loss_fct(active_logits, active_labels)\n",
        "\n",
        "        return logits, loss\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0nWUA-_hUCt"
      },
      "source": [
        "### Loss Function\n",
        "\n",
        "It is important to note the loss function that we use: Cross Entropy.\n",
        "This function measures the error of the model when predicting a certain label for a certain token. It uses the true probability distribution of the labels and the predicted label distribution in order to measure how close they are. This loss forces the model to give the highest probability to the correct category.\n",
        "\n",
        "Another important aspect is the following `ignore_index=config['labels'].X_id`, which means that we want to ignore the predictions of the additional subwords - we only care about the prediction of the first token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz7Xu5N1sp9M"
      },
      "source": [
        "## Step 3d: Training\n",
        "\n",
        "In order to train our model to learn how to correctly predict labels for each token in the sentence, we will employ a trainer function.\n",
        "The trainer works in training steps, where after a full pass on the training dataset evaluates the model on the validation set.\n",
        "\n",
        "We will use the micro- and macro-averaged Precision, Recall and F1-score, as our primary metrics, in a **strict** evaluation setting, i.e. we consider an entity as **correct** if and only if both its span and semantic type are predicted correctly.\n",
        "\n",
        "\n",
        "```python\n",
        "def train_epoch(self, epoch):\n",
        "        self.model = self.model.train()\n",
        "        total_loss = 0\n",
        "        total_preds, total_truth, masks = [], [], []\n",
        "\n",
        "        iterations = len(self.loaders['train'])\n",
        "        loop = tqdm(enumerate(self.loaders['train']), total=iterations, leave=False)\n",
        "        for batch_idx, batch in loop:\n",
        "            step = ((epoch - 1) * iterations) + batch_idx\n",
        "\n",
        "            self.model.zero_grad()\n",
        "            for b in batch:\n",
        "                if b != 'ids':\n",
        "                    batch[b] = batch[b].to(self.config['device'])\n",
        "\n",
        "            logits, loss = self.model(batch)\n",
        "            preds = torch.argmax(logits, dim=2)\n",
        "\n",
        "            total_preds.extend(preds.to('cpu').data.numpy().tolist())\n",
        "            total_truth.extend(batch['labels'].to('cpu').data.numpy().tolist())\n",
        "            masks.extend(batch['attention_mask'].to('cpu').data.numpy().tolist())\n",
        "\n",
        "            # Backward & Updates\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(parameters=self.model.parameters(),\n",
        "                                           max_norm=self.config['max_grad_norm'])\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "\n",
        "        scores, scores_trig, scores_ent = \\\n",
        "                performance.compute_ner_metrics(total_preds, total_truth, masks, self.config['labels'])\n",
        "        scores[\"loss\"] = total_loss / iterations\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "def eval(self, mode, per_class=False, write_preds=False):\n",
        "        self.model = self.model.eval()  # main change\n",
        "        total_loss = 0\n",
        "        total_preds, total_truth, masks, ids = [], [], [], []\n",
        "\n",
        "        iterations = len(self.loaders[mode])\n",
        "        with torch.no_grad():   # main change\n",
        "            for batch_idx, batch in enumerate(self.loaders[mode]):\n",
        "                for b in batch:\n",
        "                    if b != 'ids':\n",
        "                        batch[b] = batch[b].to(self.config['device'])\n",
        "                ...\n",
        "```\n",
        "\n",
        "In order to train the NER module, you can use the following command. This will start training the model and you can observe the performance on the training and validation sets after each epoch. \n",
        "\n",
        "It is important here to notice that performance goes up and the loss goes down after each iteration!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iZi6txdjQMJ"
      },
      "source": [
        "% cd /content/ai4health-nactem/src/\n",
        "# !python main.py --config config.yaml --mode train --task ner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEBL41d4s4YH"
      },
      "source": [
        "## Step 3e: Performance & Error Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjixteJ3tR4v"
      },
      "source": [
        "Since training can take some time, we have already trained the model and we can simply load it for evaluation on the validation and test sets.\n",
        "\n",
        "In addition, we evaluate the performance of triggers and entities separaterly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kql8DOd3jwF0"
      },
      "source": [
        "% cd /content/ai4health-nactem/src/\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "!python main.py --config config.yaml --mode test --task ner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmXwir_rkkGn"
      },
      "source": [
        "As we can observe, the model's overall performance is quite good on both the detection of named entities and triggers. \n",
        "\n",
        "However, there are several categories with very low scores. This is attributed to the small number of instances they contain in the training set - as can be confirmed from the data statistics in Step 2b.\n",
        "\n",
        "We can observe more closely the errors that the model makes using the following command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMYGnXY6tDNF"
      },
      "source": [
        "% cd /content/ai4health-nactem/src/\n",
        "!python error_analysis.py --gold ../data/MLEE_val.json --pred ../saved/ner-roberta-base-val_preds.json --task ner --config config.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGYIdyMplvtI"
      },
      "source": [
        "We identify three main causes of errors in the model:\n",
        "- **Type errors**: The predicted span is correct but the semantic type is wrong\n",
        "- **Span error**: The predicted span is wrong but the semantic type is correct (there should be some overlap between the gold entity and the predicted one)\n",
        "- **Wrong span, wrong type**: When both the span and the semantic type are wrong\n",
        "- **False Positive**: When the model has predicted a totally new entity which does not belong in the gold set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q48-CjmWG6zz"
      },
      "source": [
        "As it can be observed, the largest category of errors is the New entity, i.e. the model falsely predicts entities that do not exist in the annotated data. \n",
        "The second largest category is the type error, and finally the span error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mJnowZA_b-2"
      },
      "source": [
        "### Error Examples\n",
        "\n",
        "Below we show a few examples of cases where the model fails to identify correctly the target entities/triggers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw2WbaDhpGXk"
      },
      "source": [
        "## Step 3f: Visualising network internals\n",
        "\n",
        "We can visualise the attention heads of the trained model using the bertviz package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "birtb7n0Bnen"
      },
      "source": [
        "import sys\n",
        "!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n",
        "# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n",
        "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
        "if not 'bertviz_repo' in sys.path:\n",
        "  sys.path += ['bertviz_repo']\n",
        "!pip install boto3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ATpaRDtBeIq"
      },
      "source": [
        "def call_html():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min\",\n",
        "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO4EZVVZpYVJ"
      },
      "source": [
        "% cd /content/ai4health-nactem/src/\n",
        "\n",
        "from bertviz import head_view\n",
        "from bertviz.transformers_attn import RobertaForSequenceClassification\n",
        "from models.ner_trainer import NERtrainer\n",
        "from models.ner import NERmodel\n",
        "from models.ner_dataset import NERdataset\n",
        "import yaml\n",
        "import torch\n",
        "from utils import *\n",
        "import yamlordereddictloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "with open('/content/ai4health-nactem/src/config.yaml', 'r') as f:\n",
        "  config = yaml.load(f, Loader=yamlordereddictloader.Loader)\n",
        "\n",
        "config = dict(config)\n",
        "device = torch.device(\"cuda:{}\".format(config['gpu']) if config['gpu'] != -1 else \"cpu\")\n",
        "config['device'] = device\n",
        "config['task'] = 'ner'\n",
        "\n",
        "config['labels'] = ner_labels(config)\n",
        "config['labels'].trigger_types = ner_triggers(config)\n",
        "config['unique_labels'] = list(set([l.split('-')[1] \n",
        "                                    for l in config['labels'].ent2id.keys()\n",
        "                                    if '-' in l]))\n",
        "\n",
        "train_data = NERdataset(config, tokenizer, 'train')\n",
        "train_loader = DataLoader(dataset=train_data,\n",
        "                          batch_size=config['batch_size'],\n",
        "                          shuffle=True,\n",
        "                          collate_fn=train_data.collate)\n",
        "\n",
        "model = NERmodel(config)\n",
        "trainer = NERtrainer(config, model, None, None, {'train': train_loader})\n",
        "trainer.load_model()\n",
        "\n",
        "example_sentence = ' '.join(example_sentence)\n",
        "inputs = tokenizer.encode_plus(example_sentence, example_sentence, return_tensors='pt', add_special_tokens=False)\n",
        "\n",
        "input_ids = inputs['input_ids']\n",
        "attention = trainer.model.encoder(inputs['input_ids'], inputs['attention_mask']).attentions\n",
        "input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
        "\n",
        "call_html()\n",
        "head_view(attention, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sQOTxCMYSAy"
      },
      "source": [
        "# Step 4: Relation Extraction\n",
        "\n",
        "The second task  we will investigate is to predict relations between elements in a sentence, in our case, entities and triggers. We will treat this problem as a **pair classification task** and again use a pre-trained Language Model, finetuned on the MLEE dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxnIjUHgrNwO"
      },
      "source": [
        "## Step 4a: Creating relation instances\n",
        "\n",
        "In the RE task it is quite common to replicate a sentence a number of times, equal to the number of pairs contained in it. Even if this produces a lot of training instances, it is helpful for the model to focus only on a certain pair.\n",
        "\n",
        "When creating relation instances, the following should be kept in mind:\n",
        "- We need to create **negative** instances for the model to learn to predict when a pair does not share a relation\n",
        "- We need to take into account the **directionality** of the pair, so that we know which argument should come first and which should come second\n",
        "\n",
        "For our particular task, we will break-down all existing events into *relation pairs*. In particular, the *role* of an argument will serve as the relation label between a trigger-argument pair. \n",
        "Although we know that the first argument should always be a trigger, we generate entity-entity pairs as well and give them the negative relation category: \"NA\". In essence, we let the model learn that those pairs should not share any relations.\n",
        "\n",
        "Regarding *directionality*, we use the following label format:\n",
        "- 1:Type:2 --> in case the relation arrow goes from left-to-right\n",
        "- 2:Type:1 --> in case the relation should be inverse (from right-to-left)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4n99jgFGaB8"
      },
      "source": [
        "The following piece of code takes care of:\n",
        "- creation of positive and negative pairs\n",
        "- incorporation of directionality into the relation labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbWxPuy6rLkN"
      },
      "source": [
        "example_instances = []\n",
        "with open(config['train_data'], 'r') as infile:\n",
        "    for line in infile:\n",
        "        data = json.loads(line)\n",
        "\n",
        "        sentence = data['sentence']\n",
        "        print(' === Sentence === ')\n",
        "        print(' '.join(sentence)+'\\n')\n",
        "        bin_relations = {}\n",
        "        event_map = {}\n",
        "        ent_dict = {}\n",
        "\n",
        "        for ent in data['entities']:\n",
        "          ent_dict[ent['id']] = ent\n",
        "\n",
        "        print(' === Events === ')\n",
        "        for ev in data['events']:\n",
        "            print('{} ({}) -> {}'.format(\n",
        "                ent_dict[ev['trigger']]['surface'], \n",
        "                ev['event_type'], \n",
        "                [(a['role'], ent_dict[a['argument']]['surface']) for a in ev['arguments']]))\n",
        "            event_map[ev['id']] = ev['trigger']\n",
        "\n",
        "        # split into binary relations\n",
        "        for e in data['events']:\n",
        "            for arg in e['arguments']:\n",
        "                role = arg['role'].replace('1', '').replace('2', '').replace('3', '').replace('4', '')\n",
        "                if arg['argument'].startswith('E'):\n",
        "                    if arg['argument'] in event_map:\n",
        "                        bin_relations[(e['trigger'], event_map[arg['argument']])] = role\n",
        "                    else:\n",
        "                        errors += 1\n",
        "                else:\n",
        "                    bin_relations[(e['trigger'], arg['argument'])] = role\n",
        "\n",
        "        # find related things\n",
        "        print('\\n === Relation pairs ===')\n",
        "        for arg1, arg2 in combinations(data['entities'], 2):\n",
        "\n",
        "            if arg1['tokens'][-1] < arg2['tokens'][0]:  # arg1 is 1st\n",
        "                forward = (arg1['id'], arg2['id'])\n",
        "                backward = (arg2['id'], arg1['id'])\n",
        "\n",
        "                if forward in bin_relations:\n",
        "                    pair_label = '1:' + bin_relations[forward] + ':2'\n",
        "                elif backward in bin_relations:\n",
        "                    pair_label = '2:' + bin_relations[backward] + ':1'\n",
        "                else:\n",
        "                    pair_label = 'NA'\n",
        "\n",
        "                example_instances += [(sentence, arg1, arg2, pair_label)]\n",
        "                \n",
        "                if pair_label.startswith('2'):\n",
        "                  print('{} <- {} <- {}'.format(\n",
        "                      arg1['surface'], pair_label, arg2['surface']))\n",
        "                else:\n",
        "                  print('{} -> {} -> {}'.format(\n",
        "                      arg1['surface'], pair_label, arg2['surface']))\n",
        "                \n",
        "            else:  # arg1 is 2nd\n",
        "                forward = (arg2['id'], arg1['id'])\n",
        "                backward = (arg1['id'], arg2['id'])\n",
        "\n",
        "                if forward in bin_relations:\n",
        "                    pair_label = '1:' + bin_relations[forward] + ':2'\n",
        "                elif backward in bin_relations:\n",
        "                    pair_label = '2:' + bin_relations[backward] + ':1'\n",
        "                else:\n",
        "                    pair_label = 'NA'\n",
        "\n",
        "                example_instances += [(sentence, arg2, arg1, pair_label)]\n",
        "\n",
        "                if pair_label.startswith('2'):\n",
        "                  print('{} <- {} <- {}'.format(\n",
        "                      arg2['surface'], pair_label, arg1['surface']))\n",
        "                else:\n",
        "                  print('{} -> {} -> {}'.format(\n",
        "                      arg2['surface'], pair_label, arg1['surface']))\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMQb81LrvUYG"
      },
      "source": [
        "## Step 4b: Using semantic Types\n",
        "\n",
        "In order to take into accound the semantic types of the entities/triggers of a pairs we replace their surface form in text with a special semantic type token as shown below.\n",
        "\n",
        "The benefit of this technique is to avoid overfitting and memorisation of the words in the training set.\n",
        "This way, instead, we are able to learn patterns of relations!\n",
        "\n",
        "> Note: Again, we need to adjust the token offsets due to the subword segmentation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DndnclQWSHcj"
      },
      "source": [
        "First we need to make sure, that we will add these tags as special tokens, so they will not be affected by subword segmentation! \n",
        "This is done via the `additional\\_special\\_tokens` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBqhn8DkSETV"
      },
      "source": [
        "config['labels'], config['new_tokens'] = re_labels(config)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    config['model_name'],\n",
        "    add_prefix_space=True,\n",
        "    additional_special_tokens=config['new_tokens']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HU0CgG7EL5R"
      },
      "source": [
        "def insert_special_entities(sentence, arg1, arg2):\n",
        "    new_arg1 = '@' + arg1['type'] + '$'\n",
        "    new_arg2 = '@' + arg2['type'] + '$'\n",
        "\n",
        "    # insert special tokens into a sentence and update token ids\n",
        "    new_sentence = sentence[0:arg1['tokens'][0]] + \\\n",
        "                    [new_arg1] + \\\n",
        "                    sentence[(arg1['tokens'][-1] + 1):arg2['tokens'][0]] + \\\n",
        "                    [new_arg2] + \\\n",
        "                    sentence[(arg2['tokens'][-1] + 1):]\n",
        "\n",
        "    new_tokens = [len(sentence[0:arg1['tokens'][0]]),\n",
        "                  len(sentence[0:arg1['tokens'][0]]) + 1 +\n",
        "                  len(sentence[(arg1['tokens'][-1] + 1):arg2['tokens'][0]])]\n",
        "\n",
        "    # fix token ids based on BPE tokenization\n",
        "    final_tokens = [0, 0]\n",
        "    tmp_seq = []\n",
        "    for id_, w in enumerate(new_sentence):  # until 1st arg\n",
        "        w_ids = tokenizer.tokenize(w)\n",
        "        tmp_seq += w_ids\n",
        "        n_subwords = len(w_ids)  # augment id based on number of subwords\n",
        "\n",
        "        if id_ < new_tokens[0]:\n",
        "            final_tokens[0] += n_subwords\n",
        "\n",
        "        if id_ < new_tokens[1]:\n",
        "            final_tokens[1] += n_subwords\n",
        "\n",
        "    assert tmp_seq[final_tokens[0]] == new_arg1, '{} <> {}'.format(tmp_seq[final_tokens[0]], new_arg1)\n",
        "    assert tmp_seq[final_tokens[1]] == new_arg2\n",
        "\n",
        "    print('\\n'+' '.join(new_sentence))\n",
        "\n",
        "for instance in example_instances:\n",
        "  insert_special_entities(instance[0], instance[1], instance[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf_-5DezOiGV"
      },
      "source": [
        "Again, the final step is to convert the input sequence and its corresponding labels into a set of ids before feeding it into the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIHpzAFoOoMZ"
      },
      "source": [
        "from models.re_dataset import REdataset\n",
        "\n",
        "train_data = REdataset(config, tokenizer, 'train')\n",
        "train_loader = DataLoader(dataset=train_data,\n",
        "                          batch_size=config['batch_size'],\n",
        "                          shuffle=True,\n",
        "                          collate_fn=train_data.collate)\n",
        "\n",
        "for trd in train_loader:\n",
        "  for i, id_ in enumerate(trd['ids']):\n",
        "    if id_[0] == 'PMID-16407289-s0':\n",
        "      print('\\n === Sentence ===')\n",
        "      print(tokenizer.convert_ids_to_tokens(trd['input_ids'][i]))\n",
        "      print(trd['input_ids'][i])\n",
        "\n",
        "      print('\\n === Labels ===')\n",
        "      print(config['labels'].id2rel[trd['labels'][i].item()], trd['labels'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71JsYuTZyLKL"
      },
      "source": [
        "## Step 4c: Relation Module\n",
        "\n",
        "Finally, we are ready to construct our relation extraction model architecture, which will be as shown in the next figure.\n",
        "\n",
        "Similarly to NER, we feed our input sequence into the model.\n",
        "> *Note*: Here our sequence has target argument replaced by their semantic types!\n",
        "\n",
        "The we take the representations from the last hidden layer of the encoder, that correspond to each one of the arguments.\n",
        "The concatenation of the two vectors is given as input to a linear classification layer, that chooses the label with the highest probability score.\n",
        "\n",
        "> *Note*: Due to our label convention we will also know the direction of the relation!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fehab8IyuB7"
      },
      "source": [
        "re_arch = '/content/ai4health-nactem/images/re-arch.png'\n",
        "Image(re_arch, width='500')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tofsYMizDiG"
      },
      "source": [
        "```python\n",
        "class REmodelPair(nn.Module):\n",
        "    \"\"\"\n",
        "    Relation Extraction Model\n",
        "    Each pair in a sentence is replaced by special tokens expressing the entity type\n",
        "    The concatenation of the special token embeddings (after the encoder) as used for classification\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(REmodelPair, self).__init__()\n",
        "\n",
        "        self.config = config\n",
        "        self.num_labels = config['labels'].n_rel\n",
        "        configuration = AutoConfig.from_pretrained(\n",
        "            config['model_name'],\n",
        "            output_hidden_states=True)\n",
        "\n",
        "        self.encoder = AutoModel.from_pretrained(\n",
        "            config['model_name'],\n",
        "            config=configuration)\n",
        "\n",
        "        self.encoder.resize_token_embeddings(\n",
        "            configuration.vocab_size + len(config['new_tokens']))\n",
        "\n",
        "        self.classifier = nn.Linear(2*configuration.hidden_size, self.num_labels)\n",
        "        self.loss_fct = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, seqs):\n",
        "        outputs = self.encoder(\n",
        "            seqs['input_ids'],\n",
        "            attention_mask=seqs['attention_mask']\n",
        "        )\n",
        "\n",
        "        rows = torch.arange(seqs['input_ids'].size(0)).long().to(self.config['device'])\n",
        "\n",
        "        first_arguments = outputs.last_hidden_state[rows, seqs['tokens'][:, 0]]\n",
        "        second_arguments = outputs.last_hidden_state[rows, seqs['tokens'][:, 1]]\n",
        "\n",
        "        pair_repr = torch.cat([first_arguments, second_arguments], dim=1)\n",
        "        logits = self.classifier(pair_repr)\n",
        "\n",
        "        loss = self.loss_fct(logits, seqs['labels'])\n",
        "\n",
        "        return logits, loss\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTno_OzpzJ4A"
      },
      "source": [
        "## Step 4d: Performance & Error Analysis\n",
        "\n",
        "Training the model will take some time, so here instead, we will evaluate an already fine-tuned model on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvHhk1mmzaVE"
      },
      "source": [
        "!python evaluation.py --config config.yaml --task re --gold ../data/MLEE_val.json --pred ../saved/re-roberta-base-val_preds.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gxhk8QtUfgz"
      },
      "source": [
        "As we can see the model performance is high for the most frequent relation categories (e.g. Theme, Participant, etc). There are some categories with no gold labels, and some with very few training instances (e.g. ToLoc) where the model has poor performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMMdesHVVKyS"
      },
      "source": [
        "Moving on to the error analysis, we identify 4 types of potential errors in the model:\n",
        "- **Type Error**: Where the detected direction is correct, but the relation category is wrong\n",
        "- **Direction Error**: Where the detected category is correct, but the direction is wrong\n",
        "- **Entity-Entity Connection**: Where the model detects two named entities as sharing a relation\n",
        "> *Note*: Here we wanted to let the model learn that these pairs shouldn't be related in our task\n",
        "- **False positive**: Where the model detects a relation between a new pair (not sharing a relation in the gold data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NMluHfuzOiR"
      },
      "source": [
        "!python error_analysis.py --config config.yaml --task re --gold ../data/MLEE_val.json --pred ../saved/re-roberta-base-val_preds.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHjpEiPPV4tR"
      },
      "source": [
        "As we can observe, the most common cause of erros are the false positives.\n",
        "The second most common error is the type error while the model learns pretty well to distinguish the direction of the relation, as well as that entity-entity pairs shouldn't be related."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vkHUQelWsYv"
      },
      "source": [
        "### Error Examples\n",
        "\n",
        "We show a few cases of error instances of the model, on the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hT61PBQzbCH"
      },
      "source": [
        "## Step 4e: Visualising Network internals\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MuAUgloWzGU"
      },
      "source": [
        "% cd /content/ai4health-nactem/src/\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from utils import *\n",
        "import yaml\n",
        "import yamlordereddictloader\n",
        "from bertviz import head_view\n",
        "from models.re_trainer import REtrainer\n",
        "from models.re import REmodelPair\n",
        "from models.re_dataset import REdataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "with open('/content/ai4health-nactem/src/config.yaml', 'r') as f:\n",
        "  config = yaml.load(f, Loader=yamlordereddictloader.Loader)\n",
        "\n",
        "config = dict(config)\n",
        "config['labels'], config['new_tokens'] = re_labels(config)\n",
        "device = torch.device(\"cuda:{}\".format(config['gpu']) if config['gpu'] != -1 else \"cpu\")\n",
        "config['device'] = device\n",
        "config['task'] = 're'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    config['model_name'],\n",
        "    add_prefix_space=True,\n",
        "    additional_special_tokens=config['new_tokens']\n",
        ")\n",
        "\n",
        "train_data = REdataset(config, tokenizer, 'train')\n",
        "train_loader = DataLoader(dataset=train_data,\n",
        "                          batch_size=config['batch_size'],\n",
        "                          shuffle=True,\n",
        "                          collate_fn=train_data.collate)\n",
        "\n",
        "model = REmodelPair(config)\n",
        "trainer = REtrainer(config, model, None, None, {'train': train_loader})\n",
        "trainer.load_model()\n",
        "\n",
        "example_sentence = \"Regulation of the composition of the @Cellular_component$ by @Gene_or_gene_product$ : activities based on regulation of mRNA expression .\"\n",
        "inputs = tokenizer.encode_plus(example_sentence, example_sentence, return_tensors='pt', add_special_tokens=False)\n",
        "input_ids = inputs['input_ids']\n",
        "attention = trainer.model.encoder(inputs['input_ids'], inputs['attention_mask']).cross_attentions\n",
        "input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
        "\n",
        "call_html()\n",
        "head_view(attention, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gday_rSqYVnu"
      },
      "source": [
        "# Step 5: Event Extraction\n",
        "\n",
        "The final task (for this session) is to learn how to combine binary relations, such as the relation pairs identified in the previous section into **event structures**.\n",
        "\n",
        "We treat this as a binary classification task: For each generated event structure the model predicts whether it is valid (label = 1) or invalid (label = 0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51CofOMe_uPX"
      },
      "source": [
        "## Step 5a: Event Structure Representation\n",
        "\n",
        "For the scope of this session we consider we consider events as a set of relationship (argument) tuples linking NEs to the same trigger entity: \n",
        "\n",
        "> Event = {ARG_1, ARG_2, ..., ARG_n}\n",
        ">> ARG_n = (\\<trigger\\>, \\<argument_n\\>, \\<ROLE\\>)\n",
        "\n",
        "Revisiting our sample sentence:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VzoOlDmO_pM"
      },
      "source": [
        "import json\n",
        "with open('../data/MLEE_train.json', 'r') as f:\n",
        "    example = json.loads(f.readline())\n",
        "\n",
        "example_sentence = example['sentence']\n",
        "entity_dict={}\n",
        "for entity in example['entities']:\n",
        "  eid = entity['id']\n",
        "  entity_dict[eid] = entity\n",
        "example_event = example['events'][0]\n",
        "for arg in example_event['arguments']:\n",
        "  arg['type']=entity_dict[arg['argument']]['type']\n",
        "  arg['id']=arg['argument']\n",
        "\n",
        "trigger = example_event['trigger']+\"|\"+example_event['event_type']\n",
        "args = []\n",
        "for arg in example_event['arguments']:\n",
        "  arg_rep = arg['id']+\"|\"+arg['type']\n",
        "  args.append(tuple([trigger,arg_rep, arg['role']]))\n",
        "\n",
        "img = cv2.imread(example_image, cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)\n",
        "print()\n",
        "print('\\033[1m' + str(example_event['id']+'-->'+str(args)) + '\\033[0m')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TorKbeDsQL2V"
      },
      "source": [
        "### Nested events:\n",
        "Flat events are easy to directly represent as described above.\n",
        "\n",
        "The above representation does not consider the sub-structures in the case where the argument is another event trigger. \n",
        "So for a nested event as follows we would have:\n",
        "\n",
        "\n",
        "Full event representation:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnX-I-8kvpd8"
      },
      "source": [
        "example_image_n = '/content/ai4health-nactem/images/example_nested.png'\n",
        "img = cv2.imread(example_image, cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH89SQdqvqOU"
      },
      "source": [
        "Our simplified event representation however would be:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5lzru5pxbW-"
      },
      "source": [
        "example_image_nf = '/content/ai4health-nactem/images/example_nested_flat.png'\n",
        "img = cv2.imread(example_image, cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOG8QRT-xduI"
      },
      "source": [
        "As such, the following structures would be equivalent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cGoAvahxcCA"
      },
      "source": [
        "example_image_np = '/content/ai4health-nactem/images/example_nested_perm.png'\n",
        "img = cv2.imread(example_image, cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvDB4ADKAY-m"
      },
      "source": [
        "## Step 5b: Event Structure Generation\n",
        "\n",
        "How do we generate training instances? Some concerns\n",
        "\n",
        "\n",
        "*   In different sentences the same event type may have a **varying number of arguments**\n",
        "*   Some valid events have **no arguments**\n",
        "*   The same event type may have **different role-entity** argument pairs\n",
        "\n",
        "**Solution 1:** Exhaustive \\\\\n",
        "(Argument/role agnostic) \\\\\n",
        "Generate exhaustively all possible (Trigger, Entity, Role) triplets for each sentence\n",
        "\n",
        "Training set: 500K instances / 0.1% positive\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhhkwULL3_On"
      },
      "source": [
        "**Hint:** Some events would never take a specific role | entity type as argument\n",
        "\n",
        "**Solution 2:** Valid template generator \\\\\n",
        "(Argument aware) \\\\\n",
        "For each event type, generate all possible argument combinations that have appeared in the dataset at least once.\n",
        "\n",
        "Training set: 194K instances / 2%\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "def event_templates(config):\n",
        "    \"\"\"\n",
        "    Construct templates for events\n",
        "    \"\"\"\n",
        "    templates = {}\n",
        "    unique_templates = {}\n",
        "    total_templates = 0\n",
        "    total_unique_templates = 0\n",
        "    non_existent_arg = 0\n",
        "    for mode in ['train', 'val', 'test']:\n",
        "        with open(config[mode + '_data'], 'r') as infile:\n",
        "            for line in infile:\n",
        "                data = json.loads(line)\n",
        "                e_type = {e['id']: e['type'] for e in data['entities']}\n",
        "                event_trig_map = {ev['id']: ev['trigger'] for ev in data['events']}\n",
        "\n",
        "                for e in data['events']:\n",
        "                    structure = []\n",
        "\n",
        "                    if e['event_type'] not in templates:\n",
        "                        templates[e['event_type']] = []\n",
        "                        unique_templates[e['event_type']] = []\n",
        "\n",
        "                    for arg in e['arguments']:\n",
        "                        role = arg['role'].replace('1', '').replace('2', '').replace('3', '').replace('4', '')\n",
        "\n",
        "                        if arg['argument'].startswith('T'):\n",
        "                            structure.append((role, e_type[arg['argument']]))\n",
        "                        else:\n",
        "                            if arg['argument'] in event_trig_map:\n",
        "                                structure.append((role, e_type[event_trig_map[arg['argument']]]))\n",
        "                            else:\n",
        "                                structure = []  # exclude event\n",
        "                                non_existent_arg += 1\n",
        "\n",
        "                    if structure:\n",
        "                        perm_structure = list(permutations(structure, len(structure)))\n",
        "                        templates[e['event_type']] += perm_structure\n",
        "                        unique_templates[e['event_type']].append(tuple(structure))\n",
        "\n",
        "    # remove duplicates\n",
        "    for type_ in templates:\n",
        "        templates[type_] = list(set(templates[type_]))\n",
        "        # unique_templates[type_] = list(set(unique_templates[type_]))\n",
        "\n",
        "        total_templates += len(templates[type_])\n",
        "\n",
        "        unique_templates[type_].sort(key=itemgetter(0))\n",
        "        unique_templates[type_] = list(set(unique_templates[type_]))\n",
        "        total_unique_templates += len(unique_templates[type_])\n",
        "\n",
        "    logging.info('Total Templates: {}'.format(total_templates))\n",
        "    logging.info('Total Unique Templates: {}'.format(total_unique_templates))\n",
        "\n",
        "    return  unique_templates\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Sub-case: sample randomly from the generated negative instances\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Training set: 25K instances / 16% positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kszyk9aM3KLk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfNSks9d7wGC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLsoDWzo5IvD"
      },
      "source": [
        "**Hint:** Assuming a perfect RE model, the EE model would only have to choose among partial events\n",
        "\n",
        "**Solution 3:** Partial event generator \\\\\n",
        "(Event aware) \\\\\n",
        "For each event, generate all possible partial sub events (including a no-argument instance). \n",
        "\n",
        "Training set: 11K instances / 30% positive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqfz0CglAnp0"
      },
      "source": [
        "## Step 5c: Event Structure Encoding\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6IG7J1v67OR"
      },
      "source": [
        "\n",
        "*   Combine entity and role information in event encoding:\n",
        "*   Identify entities (including triggers) in sentence and replace with dedicated \\<type\\> tokens.\n",
        "*   Maintain sentence splitting\n",
        "\n",
        "Original sentence:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RFqTl3UBqMk"
      },
      "source": [
        "\n",
        "sentence_after = ['[Regulation]', 'of', 'the', 'composition', 'of', 'the', '[Cellular_component]', 'by', '[Gene_or_gene_product]', ':', 'activities', 'based', 'on', 'regulation', 'of', 'mRNA', 'expression', '.']\n",
        "sentence_before = ['Regulation', 'of', 'the', 'composition', 'of', 'the', 'extracellular', 'matrix', 'by', 'low', 'density', 'lipoprotein', 'receptor', '-', 'related', 'protein', '-', '1', ':', 'activities', 'based', 'on', 'regulation', 'of', 'mRNA', 'expression', '.']\n",
        "print('Word splitted sentence:')\n",
        "print(sentence_before)\n",
        "print('Triggers | Entities replaced:')\n",
        "print(sentence_after)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkvxuWwA66nY"
      },
      "source": [
        "config['new_event_tokens'], config['new_tokens'] = event_specific_tokens(config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "            config['model_name'],\n",
        "            add_prefix_space=True,\n",
        "            additional_special_tokens=config['new_tokens']\n",
        "        )\n",
        "tokenized_sentence = tokenizer.tokenize(\n",
        "                              sentence_after, \n",
        "                              is_split_into_words=True, \n",
        "                              add_special_tokens=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wrziIa7CimO"
      },
      "source": [
        "### EE module architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBaUs55uAnfE"
      },
      "source": [
        "## Step 5d: EE Module\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "class EEmodel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(EEmodel, self).__init__()\n",
        "        self.config = config\n",
        "        self.num_args = config['num_args']\n",
        "        self.num_labels = 2\n",
        "        configuration = AutoConfig.from_pretrained(config['model_name'],\n",
        "                                                   num_labels=self.num_labels)\n",
        "\n",
        "        self.role_embed = nn.Embedding(num_embeddings=len(self.config['roles']),\n",
        "                                       embedding_dim=self.config['embedding_dim'])\n",
        "\n",
        "        self.encoder = AutoModel.from_pretrained(config['model_name'],\n",
        "                                                 config=configuration)\n",
        "        self.encoder.resize_token_embeddings(\n",
        "            configuration.vocab_size + len(config['new_tokens']))\n",
        "\n",
        "        self.event_classifier = nn.Linear(configuration.hidden_size, 2)\n",
        "        self.arg_layer = nn.Linear(2*configuration.hidden_size+config['embedding_dim'], configuration.hidden_size)\n",
        "        self.loss_fct = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    def forward(self, seqs):\n",
        "        outputs = self.encoder(seqs['input_ids'],\n",
        "            attention_mask=seqs['attention_mask'])\n",
        "       \n",
        "        labels = seqs['labels']\n",
        "        arglen = seqs['arglen'][0]\n",
        "        rows = torch.arange(seqs['input_ids'].size(0)).long().to(self.config['device'])\n",
        "        trigger = outputs.last_hidden_state[rows, seqs['tokens'][:, 1]]\n",
        "        event_rep = trigger\n",
        "     \n",
        "        arg_repi = [] \n",
        "        for i in range(0,arglen):\n",
        "            argument = outputs.last_hidden_state[rows, seqs['tokens'][:, i+2]]\n",
        "            role_embedding = self.role_embed(seqs['roles'][:,i])   \n",
        "            arg_l = torch.cat([trigger, argument, role_embedding], dim=1)\n",
        "            arg_rep = self.arg_layer(arg_l).unsqueeze(1)\n",
        "            arg_repi.append(arg_rep)\n",
        "            arg_all_rep = torch.cat(arg_repi, dim=1)\n",
        "            event_rep = torch.mean(arg_all_rep, dim=1)\n",
        "        \n",
        "        logits = self.event_classifier(event_rep)\n",
        "        loss = self.loss_fct(logits, labels)\n",
        "        \n",
        "        return logits, loss\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOJvv4WCBAB4"
      },
      "source": [
        "## Step 5e: Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD72QS_EA_yK"
      },
      "source": [
        "## Step 5f: Error Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bkdoLlezh_s"
      },
      "source": [
        "# Step 6: Pipeline Performance\n",
        "\n",
        "Now that all 3 components have been completed and trained, we can use them in a pipeline scenario in order to do end-to-end Event Extraction!\n",
        "\n",
        "The NER component, will generate predictions for named entities and triggers in each sentence, which we can feed into the relation component. \n",
        "\n",
        "The following script will evaluate the RE component when using **predicted** named entities.\n",
        "\n",
        "What do you notice?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yN7zDJjE2m7"
      },
      "source": [
        "!python evaluation.py --config config.yaml --task re --gold ../data/MLEE_val.json --pred ../saved/re-roberta-base-ner_val_preds.json "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffFK-fVvYXlG"
      },
      "source": [
        "Performance of the model drops significantly, almost 27\\% !"
      ]
    }
  ]
}